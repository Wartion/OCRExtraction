{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ea8995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import openai\n",
    "import pandas as pd\n",
    "from google.cloud import vision\n",
    "import fitz  # PyMuPDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f11dd98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:\\\\Users\\\\prati\\\\Downloads\\\\Creds.json\"\n",
    "client = vision.ImageAnnotatorClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3777514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_and_mentioned_data = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd6150cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_image(image_path):\n",
    "\n",
    "    # Load the image\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        image_data = image_file.read()\n",
    "    vision_image = vision.Image(content=image_data)\n",
    "\n",
    "    # Perform OCR\n",
    "    response = client.text_detection(image=vision_image)\n",
    "\n",
    "    # Extract text from response\n",
    "    extracted_text = \"\"\n",
    "    if response.text_annotations:\n",
    "        extracted_text = response.text_annotations[0].description\n",
    "\n",
    "    return extracted_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a35ca716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_text(pdf_file_path):\n",
    "    pdf_document = fitz.open(pdf_file_path)\n",
    "\n",
    "    extracted_texts = []\n",
    "\n",
    "    # Process each page\n",
    "    for i in range(pdf_document.page_count):\n",
    "        page = pdf_document[i]\n",
    "        image = page.get_pixmap(matrix=fitz.Matrix(300/72, 300/72))\n",
    "        image_path = f\"temp_image_{i}.jpg\"\n",
    "        image.save(image_path, \"jpeg\")\n",
    "\n",
    "        # Extract text from the image using the provided function\n",
    "        extracted_text = extract_text_from_image(image_path)\n",
    "        extracted_texts.append(extracted_text)\n",
    "\n",
    "        # Remove the temporary image file\n",
    "        os.remove(image_path)\n",
    "\n",
    "    pdf_document.close()\n",
    "\n",
    "    return \", \".join(extracted_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1c4354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text, chunk_size, overlap):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        chunks.append(text[start:start + chunk_size])\n",
    "        start += chunk_size - overlap\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6fc578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_extract_data(result_string):\n",
    "    # Initialize OpenAI API\n",
    "    api_key = \"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\"\n",
    "    openai.api_key = api_key\n",
    "\n",
    "    chunk_size = 16000\n",
    "    overlap = 300\n",
    "    chunks = split_text_into_chunks(result_string, chunk_size, overlap)\n",
    "\n",
    "    # Initialize data extraction\n",
    "    extracted_data_list = []\n",
    "    extracted_data = set()\n",
    "\n",
    "    # Make API calls for each chunk\n",
    "    for chunk in chunks:\n",
    "        user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": chunk\n",
    "        }\n",
    "\n",
    "        if extracted_data:\n",
    "            user_message[\"content\"] = \" \".join(\n",
    "                [line for line in chunk.split(\"\\n\") if not any(keyword in line for keyword in extracted_data)]\n",
    "            )\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-16k\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": f\"Find all the data in the pdf that you think will be important to an insurance broker. The output should contain Name of the company getting the inurance, Insurance Provider, Insurance Name, Total amount insured for, How the total amount insured is split, Insurance start day, Insurance End day, Risk Location(Risk Location may be multiple, try to find them all), this is not an exhaustive list, try to extract everything you can> If anything is not mentioned, do not return anything. I do not want you to send not mentioned\"\n",
    "                },\n",
    "                user_message\n",
    "            ],\n",
    "            temperature=0.5,\n",
    "            max_tokens=4096\n",
    "        )\n",
    "\n",
    "        extracted_text = response['choices'][0]['message']['content']\n",
    "\n",
    "        for line in extracted_text.split(\"\\n\"):\n",
    "            if \":\" in line:\n",
    "                keyword, data = line.split(\":\", 1)\n",
    "                keyword = keyword.strip()\n",
    "                data = data.strip()\n",
    "                if keyword and data:\n",
    "                    if keyword not in extracted_data:\n",
    "                        extracted_data.add(keyword)\n",
    "                        extracted_data_list.append({\"Keyword\": keyword, \"Data\": data})\n",
    "    \n",
    "    \n",
    "    filtered_data_list = [data for data in extracted_data_list if \"not mentioned\" not in data['Data'].lower()]\n",
    "\n",
    "    return pd.DataFrame(filtered_data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46c69ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a5f57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(pdf_file):\n",
    "    pdf_file_path = pdf_file.name\n",
    "    result_string = extract_pdf_text(pdf_file_path)\n",
    "    extracted_and_mentioned_data = set()  # Initialize the set to store extracted and mentioned data\n",
    "    output = process_and_extract_data(result_string, extracted_and_mentioned_data)\n",
    "\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "\n",
    "    excel_file_path = filedialog.asksaveasfilename(defaultextension=\".xlsx\", filetypes=[(\"Excel files\", \"*.xlsx\")])\n",
    "    \n",
    "    if excel_file_path:\n",
    "        excel_file_path = excel_file_path + \".xlsx\"\n",
    "        output += \"\\n\" + f\"Extracted data saved to '{excel_file_path}'.\"\n",
    "        return output\n",
    "    else:\n",
    "        return \"No output Excel file selected.\"\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=run_pipeline,\n",
    "    inputs=[\n",
    "        gr.inputs.File(type=\"file\", label=\"Select PDF file\"),\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    live=True,\n",
    "    capture_session=True\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
